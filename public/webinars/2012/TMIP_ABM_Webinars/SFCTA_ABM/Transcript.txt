<meta name="viewport" content="width=device-width; initial-scale=1.0; "\>Event ID: 2033380
Event Started: 11/15/2012 7:00:00 PM
----------

Please stand by for realtime transcript. 
>> Good afternoon everyone. Welcome to the webinar agency experience using activity -based models. I am a support contractor with (indiscernible) outreach and I will be moderating today's session. Today's is a second in a new series which is an addendum to the recently completed 12 session instructional series on activity -based modeling. In this series, we are showcasing  agency experience using AV models by demonstrating how the research theory and concepts presented in the preceding series are being put into practices by agencies across the country. Our second session will showcase the San Francisco County Transportation Authority presented by Elizabeth Sall. I have a few administrative items to mention before we begin. In order to provide the best audio experience, we have automatically remotely muted all participants on lines. At the end of the webinar, we will be posting a brief questionnaire. We are interested in your feedback for how to improve future webinar offerings so we will take 897 break at the end of the webinar before the Q&A session to allow time to complete the evaluation poll. This webinar will last approximately 1.5 hours with roughly one hour for presentation followed by 30 minutes for questions. You can submit questions via the webinar room software. The pod window is on your screen and you can injure questions there. It will be posed to the presenter during the Q&A session at the end of the webinar. We are recording this webinar and will make it available on the online community practice within two weeks. The webinar is also being live the close caption for the hearing impaired. If you don't want to be the close caption, click the full screen button in the top right-hand corner and that will maximize the slide view. Finally, the information being presented in this webinar is made available for information and knowledge sharing purposes only and does not represent an endorsement. I'm very pleased to introduce today's speaker, Elizabeth Sall is the deputy director for technology services. She is active on a variety of transportation committees and serves on the planning applications and Metropolitan policy and practice committee. She is also a panel member on (indiscernible) applying GPS data to understand travel behavior. The chair of (indiscernible). Resources on advanced integration models and implementation strategy, the and she has served on several panels in the past. Thank you for your participation today. 
>> Here we go. As a process to this presentation, which I have titled SF-CHAMP, how we use it and make it useful, I would like to say this is how we use the activity base model we have. It's not just a presentation designed to be an introduction to activity -based models. There are lots of other webinar is in the library that focus on why you want to use an activity base model or my you I want to use activity -based model and why they are useful. I will focus on how we have used it and how it is used in day-to-day practices. One of the questions I get a lot is why do we have a model at all at San Francisco County Transportation Authority?  As a background, we are not and and PO. We are a CMA and California. the County of San Francisco. We have an MPL that is a nine county region in the bay area which is the Metropolitan transportation commission that are known as NBC's. We are not required to have a model here. We don't have to do air quality  conformity, really the whole purpose for the model is to answer questions. I have to say that is the fundamental reason why we have an activity -based model because it's good at answering interesting questions. with that, I will move forward with today's topic. This is a brief overview of the history. And I will focus a lot on specific examples of how we have used it and previous projects and how we have done some specific model development for some specific projects and then I will switch gears and give you a behind the scene on the day today of how we get our work done and what it looks like to work at an agency that uses an activity base model day today. a quick history of SF-CHAMP. It was developed over a decade ago. It is the longest running activity -based model and continuous use. In the world I think. Definitely in the country. There has been a lot of ongoing enhancements to support policy Project analysis. The policy questions have not remained the same for the past decade and the model has adapted to answer each of those questions. Sometimes it hasn't adapted quick enough and our directors have asked us that eventually, we are hoping to get to appoint we can turn around and answer their questions rapidly. Some of the key enhancements, this is not your decade ago SF-CHAMP. It has expanded in subtle detail in San Francisco from 190 which is the representation are them each regional model has in San Francisco which are 7-mile by 7-mile area. to 981 zones. This means every block in downtown San Francisco is has its own analysis system. We actually expanded the geography of the model, originally it was developed to do activity patterns for a San Francisco residents. Through policy needs we shall discuss in a minute we have expanded activity model to encompass the entire nine mile area. We are simulating 30 million daily trips. We have accrued the behavioral sensitivity and response to the policy questions and planning projects we have had. We incorporated value of time to examine pricing scenarios. We have examined the number of modes and expanded in San Francisco. We significantly improved the bicycle and pedestrian subcomponents of the model and included things like transit crowding which was not in the forefront of our minds 10 years ago but certainly part of our daily life in San Francisco right now. We adapted the model to incorporate that. Finally, we updated the data on which the travel miles has been built on at the last complete travel server eight we did it was in 2000, the California travel survey is underway right now which includes a large sample for the bay area and we will update the behavioral model to reflect that data in the coming future but right now it reflects 2000 household survey data and we have updated the calibration and some of the other models to have more up-to-date data from (indiscernible) data and other adjunct surveys that happened since 2000. We validate our model 2005 2010 conditions. What do we use it for?  This is not an exclusive list. Inclusive list, rather. We use it for long-range planning. We are doing a San Francisco transportation plan. Our link long-range plan for San Francisco which I will talk about later. We've used it for things, our sister agency which runs our minibus fleet has been using it for long-range planning on their capital Fleet plan and their capital facilities plan. How many buses do they need to bind the future?  We use it a lot for policy questions. What happens if we make transit free?  What happens if we have congestion pricing in downtown San Francisco?  Will we meet client action goals?  Does such and such fees have a nexus with the user?  We use it a lot for planning on specific projects. Feasibility of DOT projects. An alternative analysis for transit in certain corridors. And it is used by her planning department in all of there EIS and EI ours. In California we go through the (indiscernible) process but we go through the (indiscernible) process for almost all projects and SF-CHAMP output is critical input to the process. We have been doing a lot a work with San Francisco Department of public health on analyzing risk assessments for public health and including public health analysis and lots of projects. If you are to take those projects and map them to her our clients are, although we don't charge for all of them, a lot is other departments within our agency. A lot of it is other public agencies in San Francisco. Planning department, even in part as a region discussing there long-range planning last week. The logo on the right is environment which we have been doing some climatic action planning with and looking at our climate goals for the future and how we can meet them. and then we also get a few calls from the public on our website. You can go and submit an e-mail to me and tell me what you might be interested in analyzing and I will try and respond with Vincent with some data for whatever you are interested in. I will talk about an actual example. It might sound backwards to talk about the results before we talk about the model development process, but I want to give you a picture of what we have been using the model for. This example is cordoned based congestion pricing feasibility study. the study concluded a year ago and there are several questions we used the same physics ago  San Francisco travel model to answer. They included, what is the most effective shape and size for a pricing cordon in San Francisco?  What price.is feasible from a revenue generation?  and what are the impacts going to be, major traffic diversions, trans accounting, equity concerns?  These are all questions that our planners were asking of the trot travel model. the travel model was not quite ready at the beginning of the study to answer these questions. We had not had the foresight to think they would ask these questions. We had to go through a model development process in order to address them. Some we want to make sure the model was sensitive to all the proposed scenarios and we could generate metrics that they needed in order to do the evaluation. the initial model, which I would say we started with SF-CHAMP three. It lacked capabilities. It only had San Francisco demand. It was not flexible in relation to people driving into the city and that was not acceptable for congestion pricing scheme. It had little pricing representation and a sensitivity. Simplistic accessibility measures would (indiscernible)  not very divide desirable and not enough feedback loops to feedback information about congestion and price into things like that to her generation. There were not a lot of accessibility feedbacks. There was not peak spreading and general calibration validation was course. For this project, there was a consultant led model development project. It happened in several phases in parallel with the planning after. This included, phase one, phase two and phase three of deployable tools with increasing utility to the planners. Total process was about six months and $200,000 but the development process moved on from that and was taken over by the agency at that point to nitpick around and make sure the planners had the exact answers to the questions they needed. Enhancements directly followed those deficiencies. That were discussed in the previous slide so I won't go over those. There was a significant model development ever. Now I will switch gears and talk about the questions planners had and how that directly related to the metrics that we developed from the travel model and how that was ultimately used in the feasibility study. This is a chart lifted directly from the final report for the congestion pricing study. It shows evaluation framework metrics that were used to evaluate it's congestion pricing is feasible in San Francisco at all. I put an orange dot next to each one of those metrics that involved output from the travel model and as you can see, 15 out of 16 either directly or indirectly came from the travel model. You can see how critical the output was for informing the planning process. There was a direct relationship. It was our job as modelers to create the metrics and how planners understand how robust or not robust the answers were from the model and how to use and interpret the results. One of the first things the planners wanted to know is a part of the  this study was, what does congestion look like in San Francisco?  If were going to price congestion, what is our baseline?  We use the travel model instead of serving everyone again. To get a picture of this. We found out were a few interesting tidbits that help shape that feasibility study from the get-go. One of these is that peak period travel in the focus area is dominated by work and school trips. Not by discretionary travel. When you look at who is driving from an equity perspective, we found the majority of motorists and peak period our travelers from households with incomes greater than $100,000 per year. This is a big finding from an equity perspective the fact that people traveling in the downtown are probably not people affected by charge to ban with which is interesting to us. 
>> Where does downtown should congestion come from?  The left traffic here shows a select link of all of the links in the focus area of San Francisco which is the highlighted area. You can see a lot comes from the freeways. and a lot trickled out into the West and the South areas of San Francisco. If you look at the text, we found out this interesting fact that, well over half of peak period automobile travel in the Northeast corded area is fully internal to  San Francisco. This was a huge finding for our team. We have the tendency to blame regional travelers, those people from the peninsula and from the North Bay and East Bay coming in on our freeways and clogging our streets. Lo and behold we find out the rest of San Francisco is actually on a party to this problem not everybody in San Francisco is getting on their bikes they are in fact driving a net shape a lot of how we designed some of the more successful congestion pricing scenarios. One of the questions that we had from the get-go is what sort of shape should we look out for can just a pricing cordon on. You can see four of the general designs looked out on the left. There was a smaller downtown cordon and then if you go to the gateway scenario, what if we charge of the entry points to San Francisco?  What if we just charge regional travelers?  The double ring scenario on the top right would charge both at the entry point and  also in the downtown. and then the scenario we ultimately arrived at as being the most feasible was northeast cordon scenario. Because we found so much of the travel at congestion is coming from San Franciscans the northeast cordon performs the best and you can see that in the text at the right as well. What price.do we need to arrive at?  We tested several different ranges of prices. We found that $3 across a.m. and p.m. periods was critical. Modest enough to affect overall trip making. Meaning overall trips were not suppressed in the area. We got into a series of more refined analysis on the shape of the northeast cordon. We looked at diversions, price, revenue, and we looked at accessibility and the one down on the far bottom left corner turned out to be the winner in terms of optimizing across all of these. I will move on to comment these are the numerical results on how accessibility is changing with the fee. We found that with the northeast part in charge daily trips to and from the focus area increased under this scenario which is an increase of accessibility, increasing transit accessibility penalizing autos but the people traveling and autos are getting a better quality trip. We are getting more people moving which is a good thing. One of the questions planners ask is which scenario works best for peak auto trips?  You can see, the northeast cordon scenario is the best for decreasing congestion or peak other trips in the northeast cordon which is not surprising. The southern gateway or gateway scenarios that are best at reducing congestion too and from the south part of San Francisco. Not very good we found at reducing overall congestion in that congested part of San Francisco. This is an important finding on the southern gateway scenario might not be sufficient for mitigating congestion which is one of the biggest objectives. Where are the vehicle true productions coming from?  This is an analysis of who is reducing their travel as a result of the speed. The northeast cordon is a  is a lot of San Franciscans reboot using their travel because it's cheaper for us to provide alternative transit service and excess abilities to and from San Francisco that I might be to and from the South Bay or something like that. We also looked at the economic benefit. One of the interesting things here is that other regional Bay area residents actually accrued significant economic benefit from the reduced congestion that happened within San Francisco because there were ripple effects throughout the network. We need to find out if this was feasible from a revenue perspective and we found the entire program would generate between $60,000,080,000,000 in annual revenue. I'm going to pause for a second before adjust the slide and say, none of this would have been possible or reasonable had we not had a activity -based model. the continuous value of time is critical for analyzing these different scenarios and even the concept of a tour is critical. Not considering you're entire day plan or the fact that if you drive into the told area in the morning and drive away in the evening that you need that mode choice in the evening depends on your choice in the morning. One of them being told and one not. That was critical for coming up with a feasible congestion pricing analysis. the model is really great for congestion pricing study in fact we have a tear be paper talking about that. We have developed a wish list for future development on stuff we felt like the model and put Asterix on them. One of them on the left is that we felt like the model did not do a stellar job at analyzing parking. We have been asked to analyze, what if we charge for can go on parking instead of a congestion charge on the cordon and we did not feel like the model did a stellar job at that so we have done to model development since then to direct address that. On the right, you can see a picture of the streets in San Francisco  could there  that there  could there our spill back of facts past the red light. Certainly, one of the things we look that when we evaluated different congestion pricing scenarios was the overthrow of diversions from an over told area. How much of those versions which you can see in this crap over here, the red representing increase in traffic from the told scenario, which we don't use anymore, that represents a ratio of greater than one. How many of those people would wait out that congestion or how many people would pay the toll?  We felt like for this reason revenue projections were pretty conservative. Nonetheless, it is on the to-do list and we are developing a traffic deployment model to address these issues. Example two, San Francisco transportation plan focused on model development that we have done. the goals of the plan there are four of them. To strengthen their Mercedes regional competitiveness. To provide world-class service for infrastructure. Ensure a healthy environment and create a more livable and equitable city. I will go over some of these initial analysis we did on some of the baselines for creating and setting the scene for the trek San Francisco transportation plan and talk about the deficiencies  and somebody's analysis and then I will move on to address it. One of the questions related to one of the goal areas is how can we reach economic competitiveness goal. the metric that we have adopted for the purposes of this study has been travel time and cost of the commute in the morning. You can see, a grasp of the Green representing  agreement representing the travel time and cost of commuting from different places or two different places from all around the bay area. for different commute centers. So a commute to downtown San Jose it is represented by this green arrow versus commute to downtown San Francisco is slightly more expensive today. This represents commute by car. You can see that in the future, that class is expected to rise significantly based on our modeling results. More in San Francisco than other areas. At first we thought that was opaque as we wanted everybody to commute by train said but then we looked at the next graph. Here you can see every other city is doing better in 2035 then  2035 than they were in 2010 for transit costs and travel times except for San Francisco so this raised an alarm to us that we need to be addressing our competitiveness and how do we get people to downtown San Francisco in a competitive nature. We go we did an okay job at answering this question, the model is designed to do this. We think it did an okay job at answering this question, how can we reach our environmental goal?  One of the some questions to that is who is producing greenhouse gases in the future?  This  graph on the right represents greenhouse gas on production per household with autos. If I live in this zone, how much greenhouse gases does my household produce and the entire day. Driving all around the network. This is easily done in an activity -based model because we know even though a person might be making a trip from here to hear they will  here they would might live over here. That information is attached to them throughout the whole day. It's easy and you can see the people who live in downtown San Francisco did not produce that much greenhouse gas and the people on the outskirts tend to produce a lot. We have this data for the region. On to showing up for San Francisco cause its easier to digest. That goes back to the point we found congestion pricing study that most of the drivers in San Francisco are San Franciscans. Here  is a picture if we were to examine the travel market in the future of where is the new iMac coming from?  We see that it's coming from the outskirt areas to downtown from the Southeast (indiscernible). But not in the Outer Mission which is served by regional transit. This is an interesting finding. We analyze several different strategies and the general thing you need to get from the slide is essentially that, we can put all the strategies together and would not come close to San Francisco's and the state's ambitious greenhouse gas cools but the thing I want to focus on is that I put all these Asterix on these and that is in the course of these analysis we found we really weren't analyzing the strategies to the best of our ability and SF-CHAMP. In the transit scenarios, we put a lot of transit in them but it turns out our model was incapable of analyzing the impact of higher transit passes a. It was not sensitive to that. We did not have a transit crowding model. Everybody to get on transit that wanted to so building more transit had limited value. The second would be bicycles. We felt like we were doing a great job at that time of measuring the impact of the Viking infrastructure. We could measure, we had pedestrian and in bicycle environment factors that we could turn on or off pursuing a  places good or bad and we had a stick approach where we could take a based on a traffic but that does not guarantee they would get on their bicycle and a was a crude approach. One of our goals was how can we reach our transit capacity?  Where are the capacity issues in the transit system?  Where our latent demand for transit?  Or using our tool we had at the time, we could not answer that question very well. I could show where the volume capacity on transit might be to but I could not tell you whether or not those people had another route to ride on or whether those people could drive in the future. That was a problem. As I said, we could not represent what if we build bigger buses or ran more buses?  Would that mitigate our crowding or would latent demand just sell it?  Which is a good thing. These are questions we felt like we did not have answers to. Similarly, how we can we reach the livability coal which is getting less than 50 percent of our trips to and from San Francisco taken not with cars. This involved getting people on bicycles, getting people out walking and we did not have a great way of representing the effect of bike infrastructure. As you can see, this is a nice bike lane and here is a public realm project in the Mission. We had no way of representing these in the model other than taking a lane of traffic away. We underwent a model development. The things we needed to increase sensitivity to work bike infrastructure, walked conductivity and the quality of the walk and transit crowding. I will discuss each of those. How to represent the effect of bike infrastructure. We felt like in order to do that we need to develop a bike route choice data. Model in order to do that we needed data and we needed it cheaply because we did not have a ton of budget to do this. Although we did have (indiscernible) which we were appreciated for. We developed this cycle track smartphone app. It is used by a dozen agencies across the country. That was developed by a contractor and the android version was developed I (indiscernible) about pictured here who is the predecessor deputy director for technology services. the cycle track application ask for a little bit of information about who you were, how good a biker you work and at how to log the trips you took on the bike. This is an example of somebody using it. What we got from that was a bunch of GPS data points as you can see here. This is raw GB at GPS data points. That was step one. Step two was hiring a smart intern to do something with all that data. Jeff Hood pictured here was an intern for us and he took these traces we collected with cycle tracks, applied some smoothing to it, split them up with a different trick and did some identified ones that were not bikers. Heat map matched and provided us were very appreciative that we did not have to re-create the wheel. Jeff developed an algorithm and you can see here because in order to develop a route choice model you need to know not just the route taken but evaluate that against a route not taken so here is the route that was taken by the cycle tracks user and all of the color graphs are the routes that Jeff generated essentially using (indiscernible) method. There is a paper in transportation letters the details that. It was published two years ago in transportation letters. and then we used (indiscernible) to estimate a path sized loggia model to figure out whether the attributes make people choose different bike infrastructure and coated them model into Python. You can see here we found out that bike lanes if you divide this, people are willing to travel twice as long if they are using a bike lane and if they are an infrequent cyclists, that is times more. Bike lanes are essentially very important for people. for the most part, we were surprised by this finding that being able to quantify it was important. We were able to quantify how much people dislike Hills. Not dwelling on that, -- we needed to turn this into something that (indiscernible) could use. So added Python code to be able to calculate bike route choice blog some that we use for  choice model estimation. This is a sample of the map if you are coming from this area, you can see the blue beans a better bike route choice and read it means I don't feel like biking they're ever. You can see that these hills are not the best place to bike. Green areas are flatter and places I would consider biking but really, this does show where Lisa likes to bike. She tends to stick to the blue areas and we have confirmed and match lots of other people bike route choice and confirmed that they made sense as well. One thing that is critical about doing this is having a two or base model. If you did not no, the to her base model is essentially knows that if you bike down this hill you will have to bike up it at the end of the day at some point. That was critical to making this whole thing makes sense. I also  mentioned we need to represent different walk qualities. Lisa wrote a past generation algorithm in Python which we also use for transit access that follows a generalized costs and instead of (indiscernible) skins things like slope, density and street capacity and measures and directness of path which we can feed into our mode choice model and what that means is essentially we do not have people, this being a destination, this being a giant hill, it means you don't have people taking the shortest path over big hills that you represent the fact that people are going to be walking a long way around those hills and there is a utility for doing that. the final thing we said we wanted to fix and this model version was transit crowding and taking that into account. We knew some of our ridership forecasts were unrealistically high for specific lines. We had poor line level evaluation for suggested core doors. If we had three different transit reps on the quarter were one being high-frequency and the other thing lower frequency, everybody would flock to the high-frequency core door. We would not see spillover onto the secondary lines which is what we see in real life. There was no relationship between a capacity of  the capacity of the line and the ridership of the line. We hired another smart intern for this task he first estimated a dwell time equation as a function of vehicle type based on APC data. This allowed us to show more people boarding a bus made the travel time of the bus lower. This including this alone showed a penalty to those buses that stop everything .-full-stop and had 10 people get on intend people got off. That could be route represented in the model. He and Lisa developed and capacity for transit assignment. We run the assignment over and over again. There is a paper published in transportation and in the Notes section of  notes section of this PowerPoint if you are interested in the process. Our transit assignment got a lot longer and takes many hours for this process to complete but we are pretty happy with the results. Than we needed a way to put this all together so we hired another smart intern. He put it all together and estimated new mode choice models with congested transit scams the walk path variables and bike route choice blog sums. After he was done, he and Lisa had the pleasure of learning about model calibration. And then we had another intern who helped us develop calibration validation targets. These guys, put together a new model version for us and that was awesome to have accomplished in house. This new model version woman look at the sensitivities, a quick overview of that. There are presentations about this in several different forms. Most recently the innovation conference. This looks at the trip difference if we incorporate bike projects. This is the difference in trip by mode or actually is as daily tours. This is the old version of the model without an improvement in this is the new version. and the old version, what you see is a stick effect. Creating bike projects involve  taking away auto lanes so there are less people driving. Which is expected. But then where are they shifted to?  It was all over the place. There was nothing to tell them they should be biking instead of walking or biking instead of taking transit. This was not the effect we wanted. We could not say many more people were biking. And it caused transit crowding problems which is not what we wanted. One of the reasons we want bike infrastructure was because it can help you alleviate transit crowding problems. Fast-forward to the new version, where we have this lovely ^-caret including the Vikings could structure. What you see is this stick effect of people not taking auto. We relieved some of the transit congestion. People have been enticed to bike around the city which is an awesome result to see. If we look at that for what we call livability projects which means making things more walkable, you can see the same thing has happened. In the stick approach for Harold, we have a lemonade and a bunch of auto trips which is a good thing to do in San Francisco. But they have not necessarily gone to anyone mode here. If you look at it in fury, we have enticed some people away from auto and they are disproportionally going towards walking. Which is exactly what we hope to see. We haven't been able to use it, we are in the process of using the model for evaluating projects for the San Francisco transportation plan. We are coding networks as we speak. We haven't used the model version for other studies. One of them was a transit travel time improvement study, what happens if we included different transit travel time and improvements?  Travel time on transit goes down?  Crowding actually goes up with this. That means if crowding goes up, we also have an increase in the travel time slightly that as a result of that. More people are getting on and off the bus and it takes time. Your trip will take a lot longer if 10% more people are riding the bus. There's a lot more stop and go had a lot more waiting for people to get on and off the bus. Well we do was interesting is looking at this graph, this is a distance by transit for transit trip. It is a frequency distribution  of -- a difference in the distribution rather. With the travel time improvement we saw a decrease in the amount of short transit trips. That was interesting. We saw a lot of increases overall. What we saw was because all of these people got on the bus earlier on, all these people could not get on the bus because it was to crowded. These are the people switching to walking and biking. That was an interesting finding. It's exactly what happens in real life. We are excited to see this captured in our model. There are a lot of questions we have not answered. with this version of the model or San Francisco transportation plan, our planners are always asking us for more and challenging us so I will run through a quick list of the questions we are trying to answer. We are in thought process of how to address them. One is about the school travel, how is that  handled by a family?  What about school choice, in sentences go the problem is not necessarily most people don't go to their neighborhood school. There is an interesting school selection process in San Francisco that has gone on where people living here go to school over here and that sort of thing and that's a hard thing to predict. Not only that, it's a hard thing to predict for what will happen in 20 years so we have been struggling to address that. School travel is important no. 50 percent of small in nature, 50 percent of people get to school by auto still or family vehicle which is not a stellar number for us to were trying improve that. Providing more access to car sharing reduced or give people more access to driving?  Is a question we have been pondering in San Francisco as there are now thousands of car share members in the Bay Area and an increasing number of car sharing operations and ways they operate. It's not just zip car it's peer-to-peer car sharing and all sort of one-way car sharing that are happening now. Policy questions that we are addressing, does requiring a transit pass purchased for everybody who might be a new mega- development does that mean they will use it?  How does that affect transit when transit ridership when the marginal cost of writing transit is not think or parking cash out we haven't been able to address that will in the model either. It's a question we would like to be Mansour. Going back to the sharing of different modes, sharing not just cars that scooters, liquid for bicycles and we have this map in the corner is the pilot area of the bicycle sharing project which we'll be underway shortly. There are many ways to get a ride in San Francisco is not just hailing a cab anymore which is fairly limited in San Francisco. We have lift, people driving around that peak mustaches ready to pick people up. We have Uber which is everybody's private driver. We have lots of other ways to examine that cab drivers and services go so in some ways, people are driving a lot more and we don't have cars and we got to figure out a way to capture that. At the same time, private transportation options have become an employer benefit. Thousands of people commuting to Silicon Valley you via the shuttle system. This is a map that (indiscernible) put together a month ago to show mass quantity. Surveys that we have done as part of the studies here at the TA have shown that 50 percent of these people would have been driving had it not been for private employer shuttles which is an interesting statistic and it's not just the shuttles for mega- employers there's something called right how were you can vote for a shuttle to be provided between your origin and destination and when they get full they put a shuttle and service. This has change the landscape of transportation on the peninsula. These personalized transit options didn't exist, would people even make a trip to work?  This is a picture of some Mike were things like Flickr were developed before they got bought up by yahoo. People don't work at these places and we have not identified (indiscernible) as a primary workforce destination for these workers but it is for all intents and purposes in real life. The people aren't the only flexible par. The attractions are flexible to. This is an example of food trucks which is easy to laugh out but I think increasing in the future we will be having to forecast people going to these parking lots or other unintuitive destinations. It's not just about the math of supply and demand. There our utility functions. If factors and pure effects. Mike mode share did not increase any bicycle infrastructure at all it just became cool to ride bikes. If you did not ride your bike on an afternoon, you are not cool. These are the things we are thinking about for the future. It's not just all about travel time and reliability, sometimes you can make an even terrible bus ride fun if you have the right game. This is an example of an app called mutiny. a play off Muni. It was developed at a hacker gone a few weeks ago that I attended that made a game out of how smelly and vomit ridden your bus might have been and you get stars in points for that a foursquare for riding the bus. People are attracted to the strange things like being packed like sort Dean's I don't think everybody will flock to it that it is something to consider. I will switch gears and give you a behind the scenes look of what we do date today. It basically breaks into three categories. Model applications, development/research, and  maintenance. Maintenance is small because the idea is that all of our we want to make our day interesting and higher people that are interested in doing things other than pushing paper and clicking buttons on that were coding. We have done is we have automated as much as possible to reduce the amount of maintenance we need to do or step I would care that categorizes maintenance. So we get to exercise our planner brain at all of these meetings and digesting output from the model. and also doing research and coding stuff into the model and writing papers which we find to be more interesting. One of, you also noticed the network coding model babysitting I made those really small boxes for the most part they are not what we spend a lot of time on every day. We've automated this process is much as possible and sometimes we have been babysat the model closer crashes every once in a while but it is not something we spend a lot of time on. We spend our time developing tools and doing thinking at meetings with planners and digesting output. A few steps we have run we have run SF-CHAMP 200 times 600 times as 2008. We had a high point in 2010 during the pricing study when we ran them 243 times. I documented full model runs but that was pretty impressive and our server room was definitely heated during that time. We prefer to do about one model run per week and that's certainly not our capacity we can do more than that but what it is is we like looking at the output and having time to put on our planner hat and think about what they mean. Do they make sense?  What is interesting about them?  There's so much data that comes from each model run that we are interested in learning about. On the development research side, we have done a lot of reading on research and identifying the needs of planners and we spend a lot of time developing new tools which is fun. It means we go to places like (indiscernible) and talk to people about it. These are the people behind the curtain. These are the modelers. Dan, Lisa and myself. Here are the key planners who we interact with the most. I put them in their official boxes to make a point but I'd also like to point out that (indiscernible) our executive director is really the inspiration behind using models and our day-to-day planning. We are eternally appreciated for the devotion he has two that (indiscernible) base model. How it works, the modelers and the planners don't necessarily meet separately we gone the same retreats and are in the same projects and we worked together. I included the interns as well. We are one big team working seamlessly together. The modelers go back to their cubes and code in every single planner on the planning team understands how the model works and understands that caveat and that is key. One of the great things about having an activity -based model it is is not hard to figure out how works, it makes sense and works with a persons brain instead of productions and attractions. They can run through the simulation of the day in their head and think about how the model will work which is really awesome. We have consultants. These are not all of our consultants. And one of the great thing about our team is Jennifer our current intern is that we come from a diverse background and what we have diverse interests and diverse professional development goals. It makes for an interesting team. I took a picture of Dan at his desk and he has a Python book because he is trying to learn Python and Lisa has a computer science degree is an expert in Python so there's a lot of cross learning and it doesn't mean everybody on the team needs to be a Python expert though we can each have our specialties and each have our growth areas. I have plenty and we have people with less traditional backgrounds. Jennifer does not have degrees in civil engineering or planning that she is doing a great job as an intern interpreting model results and we are excited to accommodate people from diverse backgrounds who are showing up interested in modeling and one thing everybody has in common is that they are interested in making and using facts and models and analysis to make samba and Cisco a better place to live. and work. It is a fun team to work with. One of the key aspects of this team has been the interns and a continuing supply of smart interns who have taken on huge projects. I want to make a point in the model development process that that was done by interns. Under the direction of staff and with a lot of leases help we really leveraged our intern program to do a lot of the development. At the end of the day, date and up with a tear beep paper a couple of presentations and we end up with something we find valuable. This is a timeline of the interns since I started. You can see we have hired to, and several others have gone on to various travel modeling careers but I feel like that program has been very successful. I will talk about some of the more mundane tasks. Everybody's favorite is network coding. We tried to make network coding less painful. What we did was develop something called the network ring or which is a Python library. You can find it on our site. This breaks each project down into a coding and Python. This is an example for the West Dublin BART station. If you can read the whole thing I might make sense. This is saying, West Dublin is this node and I would like to turn it on. I would make could turn on. It has some other information about the fact that it is supposed to be implemented in 2011, compatible with the most recent champ version but essentially every time we code West Dublin station we are not clicking on a point where making sure something is connected or adding a line true program, we are calling this command. We can update this command to make a more up-to-date if the coding for West Dublin got to be more up-to-date. That example is here, we are version controlling each project so this is an example for an express bus lines, express from candlestick.. You can see we've updated the coding. You can see that the coding needs to change if we add a stop, or we reroute it in case the candlestick interchange has not been implemented yet, we can add these changes and you can see this is a version that is compatible with (indiscernible) we have those same changes exist here. It wasn't that we coded them twice. We could pull these changes onto these changes seamlessly. It has been so easy to manage different versions of the network. We can pull different tags so this tag represents the fact that transit effectiveness project in this version and we can always go back to that version and it will be compatible with this project. It has been very helpful. What does that mean for when we actually build a scenario?  the network wrangler builds a scenario by a project list and a tag so in this case (indiscernible) our entire scenario is built from this Python code that list each project we want to include. We can also do something easy like build every project in our library that goes outside of San Francisco up until 2030. In the committed category. So there's a lot of flexibility here. A limit errors from network coding. And it allows us to reproduce every single scenario we have ever done in the past via both these tags and the title. 
>> There's also functionality for error checking afterwards. Is this really what you meant by the re- coding of this line or is it not?  This represents a difference between a baseline scenario and the scenario we have coded for a certain scenario. and we send this to planners, we sent this map to the (indiscernible) for them to review and make sure that was exactly what they meant so we don't have to run the model twice. Everybody knows what's in the model so only look at the results we can see what changed. It's a lot simpler for everybody. We also use get for version controlling our model as well. It's a great tool. We have it each series of blogs of check and that it happened in the past few months, weeks it looks like. and then we have different tags so this is the tag for this (indiscernible) that we have just completed the modeling for. Then we can look and see what's changed in each version so we can say, what is the difference between the (indiscernible) version and the version we use for congestion pricing study or recover that the code and it will tell us that this line was deleted and this one was added. This has been useful for figuring out if there is a change in the data or how the  have the model is dealing with things, this is the go to source for that. We keep each model version ready to run essentially. So if we need to go back and run something from an E. IR three years ago, we have a cached version in our network that we can pick up and go with. There's a few different strategies for using version control. I won't go over this in detail but this website has a great information on it. Essentially, you develop a branch branch -- a development branch. If we want to develop a certain feature like at transit crowding, this would be that branch. As soon as this is ready gets merged back into the development branch have lots of feature rich is going on at once. This is transit crowding, bicycle scans, making the model faster and you can merge it all back in and pull different versions together to make sure they are synced up. If we found a bug  in the model and need to fix it, that's what this hot fix branch comes from. Not only would you merge that hot fix back into your master branch, you then will tag it with a different version number and pull that into the development branch. So that is a crude review of how you might use it and that's how we try to use it. We are not always perfect our version control branching scheme but I would recommend people looking at this as a resource. In terms of the machines we have. We are lucky we have a lot of machines although some are nearing the end of their life. We try to keep two stacks of high-powered machines able to run models of the same time so we can run to a once. We reconfigure this to run for models the ones but not as fast. We try and keep that to so we have each of these is a machine, each of these ring ones have eight processors, 16 cores and 32 gigs of RAM. It to the smaller ones has four processors with 16 gigs of RAM. These green ones are what we used to run the core part of the model and most of the model and then we use the extra machines who are the older machines, highway assignments and transit assignments and things that are highly to strew bootable across all of these processes but we don't use them for the core parts of the activity model. We have taken one of our processor machines and devoted it to DTA assignments as well. We run everything from the server that is not backed up. Two terabytes. We are prepared to basically everything on here we are prepared to lose it can be re-created by step that is backed up on our camp directory and that includes model source code and network source code and that is backed up hourly so anything they're we've made changes to where you have a record of and should not worry about it. We might lose a model run that everything  but everything is re-created well from that. Two terabytes is not a lot of data for a bunch of activity models so we are constantly backing these up two different hard drives redundantly. Very low tech way of backing up and works for us. In terms of how we distribute the processes, we have two ways to dispatch things. One is we have a Python developed dispatcher that Billy wrote. Distributes a list of jobs the two different machines. We also have something Billy Rowe called Python cluster which creates the distribute multistep wrapper around a whole list of the cube strips. We might feed it 10 different transit assignments and it will create a distribute multi- stack were each one of those tend to get distributed to a different Cuban node. That way we've made all processes distributable which is good because we do a lot of computing. Running the model is simple. Network coding is simple, as long as we have the projects coated we run a Python script. It even produces maps automatically. And running the model is simple to. We need to set a few basic things like what land-use do you want where are the networks, what can't version do you want, and then we set what machines you want to set it to. How do you want to distribute the processes. and we hit go and usually it works. That's all we do for running the models. Pretty simple. A few last words, and what else we are working on. We finish the citywide model includes data on every hill every signal and every bus on every road. It's all creative private matter?  From our static network on the fly. We had a peer review in July and this is a picture of the network here here is that v-victor of the people that have worked on it. You can find out more about that by going to our website. We have been working with fast trips at the University of Arizona. Here is the main developer who is our intern over the summer and the work he develops as the initial version and mark Hickman is the advisor and Lisa helped out as well. Here's an example of an individual transit trip, this is an example of (indiscernible) outbound that departed that 3:00 or something like that. This is a validation of the individual trip not all the trips that went along that line on the court order that you can see there are several different (indiscernible) tested out in fast trips. This one I'm tracing is the (indiscernible) equilibrium and we also have the small dogs represent automatic passenger counter data for that trip. You can see it is not perfect though we are pretty impressed it was so close on the first try without in the additional calibration of this process and we are excited about using this in the future to supplant our work around transit crowding that we developed and I highlighted earlier. In order to support not just our DTA model that support lots of clinic studies in that city, Lisa and our intern developed in all open source web-based database on using (indiscernible) where essentially we standardize and lay out all traffic count taken in the city. We developed an input format where people can submit the counts and map them. It's not quite operational yet, it works but if you know how to work it correctly I guess. That's also a open and available on the website. With that, I will finish. These are the e-mail addresses for our modelers and myself. They can ask answer questions and our website which has lots of information. All take questions now. 
>> Thank you Elizabeth for that detailed look at the activity. But we will do now for about one minute is allow time for the participants to take this quick poll and there are a couple questions that have been submitted. I will poses for Elizabeth and we can get her input. We will give about 60 seconds for people to make their way through this quick poll. Elizabeth, one of the questions they came in when you were describing the walk and bicycle improvements that went into the theory version of the model is whether you have done in a validation within a bike and walk project improvements? 
>> We have for the bike improvements. Not what the final version of the model but we have a lot of bike counters across the city. We did a validation. We had a graphic that I did not include. Where we are over and under on a count. One of the places we were under was under the along the waterfront were a lot of people visitors and tourists rent bikes and we are not capturing that yet in the visitor model which is crude at this point but we hope to in the future. I would say we don't include trips but other than that what we do a good job on the initial validation. For walks troops walked trips we haven't. I don't think our current walk assignment is robust enough at this point. We are looking forward to getting a lot of GPS surveys that are going to be coming from the California household travel survey and doing more robust look at that than I don't think at this point in time it is worth looking at I can't imagine we are getting anything correct on the number of people crossing such and such intersection. 
>> Is a related question, if the fury version of the model does better in terms of transit validation compared with the here old? 
>> Our versions are named after our pets. Yes, you can look at the paper we published in transportation this past May that details the transit crowding algorithm where we actually and our poster from last year that that paper was derived from where we actually do a validation and show the difference in the validation along a certain core door and how it affects it. 
>> Another question  that came in was, asked about the Google car and whether they thought San Francisco was a pilot study and I guess what they are referring to is the Google driver list car perhaps? 
>> We haven't thought about that but I'm sure it could be added to the list of things that we are brainstorming and thinking about. I have not seen a bunch of them on the street so I'm not worried about them as I am about the other things I mention that I see happening all around me all the time. Certainly something we cannot the list. 
>> I think I remember seeing a picture of one trying to navigate (indiscernible) Street. Another question was, what specific health effects you've analyze? 
>> I am hard-pressed to remember the specific ones. Obviously, the health department is interested in levels of physical activity. They have been interested in the number of miles that people have been walking on a daily basis and who is walking and wire. They are also interested in exposure to particulate matters. The public health department did a fairly lengthy study at on study to look at the health impacts of our congestion pricing feasibility study. That was presented a few years ago and I'm happy to provide somebody with the information to get in contact with the project manager for that in the report but we have only been providing outputs and they have been the ones to analyze them. 
>> Someone has asked the question after you asking you to describe the integration of urban center with the activity base model? 
>> We have an urban model in San Francisco. Which is designed to allocate land use to the projected buildings (indiscernible) in San Francisco based on a controlled total set we use from the region. It works in terms of an integration to a land-use integration but we don't use it as they are main model. Partially because of time implications for running a complete integrated model and also partially because we feel like within San Francisco it is a lot easier to find out where things are going without an urban model there is not greenfield development happening. The urban model we have we could spend a lot of resources and develop it and make it a lot better but we are focusing on is actually our region developing that and (indiscernible) are certainly diving headfirst into urban model and using it for there RDP this year so we are more focused on supporting them with their development than within San Francisco development of it. 
>> Thank you very much. I will give folks still on the line an opportunity to enter another question or two. In the meantime, I'd like to thank Elizabeth for taking the time to prepare and deliver this webinar and for sharing the experience of her team. If you have any questions or comments about the material presented, please feel free to e-mail feedback at (indiscernible). I want to remind everyone that our third session in the series will be presented by (indiscernible) from the Denver regional Council of governments on Thursday,  December 13 in the same time spot. I don't see any additional questions. So that will conclude today's webinar. Thank you again, Alyssa that. 
>> No problem. [Event Concluded]> 
>>  [Event Concluded]